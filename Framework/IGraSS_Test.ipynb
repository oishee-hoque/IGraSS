{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd2b75-8bb1-4c42-a2c6-7fcc11429b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from configure import *\n",
    "from deeplabV3Model import *\n",
    "from network_utils import *\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0d9f4-ef27-4f94-b650-7b032ce9b941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_predictions(weights,image_patches,model=\"DeeplabV3+\"):\n",
    "\n",
    "    ## loading the trained model\n",
    "    if model.lower() ==\"deeplabv3+\": \n",
    "        trained_learner = DeeplabV3Plus(image_size=p_s, num_classes=NUM_CLASSES)\n",
    "        trained_learner.load_weights(weights)\n",
    "    elif model.lower() == \"resunet\":\n",
    "        trained_learner = ResUNet((512, 512, 3))\n",
    "        trained_learner.load_weights(weights)\n",
    "    elif model.lower() == \"resnet\":\n",
    "        trained_learner = sm.Unet('resnet50', \n",
    "                input_shape=(p_s, p_s, 3),\n",
    "                classes=NUM_CLASSES, activation='sigmoid')\n",
    "        trained_learner.load_weights(weights)\n",
    "\n",
    "    # image_patches = get_img_patches(years)\n",
    "    image_patches = np.squeeze(image_patches, axis=2)\n",
    "    \n",
    "    predictions = []\n",
    "    for i in range(image_patches.shape[0]):\n",
    "            predictions.append(trained_learner.predict(image_patches[i]))\n",
    "    return predictions\n",
    "\n",
    "def create_subgraph_around_terminal(matrix, terminal, radius):\n",
    "    rows, cols = matrix.shape\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    directions = [(-1, 0), (1, 0), (0, -1), (0, 1), (-1, -1), (-1, 1), (1, -1), (1, 1)]\n",
    "    \n",
    "    t_x, t_y = terminal\n",
    "    for i in range(max(0, t_x - radius), min(rows, t_x + radius + 1)):\n",
    "        for j in range(max(0, t_y - radius), min(cols, t_y + radius + 1)):\n",
    "             if matrix[i][j] < large_val:\n",
    "                    G.add_edge((i, j, 1), (i, j, 2), weight=matrix[i][j])\n",
    "    \n",
    "    for i in range(max(0, t_x - radius), min(rows, t_x + radius + 1)):\n",
    "        for j in range(max(0, t_y - radius), min(cols, t_y + radius + 1)):\n",
    "            if matrix[i][j] < large_val:\n",
    "                for di, dj in directions:\n",
    "                    ni, nj = i + di, j + dj\n",
    "                    if 0 <= ni < rows and 0 <= nj < cols and matrix[i][j] < large_val:\n",
    "                        G.add_edge((i, j, 2), (ni, nj, 1), weight=0)\n",
    "                        G.add_edge((ni, nj, 2), (i, j, 1), weight=0)\n",
    "    \n",
    "    return G\n",
    "\n",
    "\n",
    "def find_shortest_path(G, terminal, sources):\n",
    "    # G = create_transformed_graph(matrix)\n",
    "    terminal_node = (terminal[0], terminal[1], 2)\n",
    "    shortest_distance = 999999999\n",
    "    best_source = None\n",
    "    best_path = None\n",
    "    source_nodes = []\n",
    "    try:\n",
    "        length, paths = nx.single_source_dijkstra(G, source=terminal_node)\n",
    "    except nx.NetworkXNoPath:\n",
    "        print(\"None\")\n",
    "\n",
    "    path = []\n",
    "    for source in sources:\n",
    "        s = (source[0], source[1], 1)\n",
    "        if s in length and length[s]<shortest_distance:\n",
    "            shortest_distance = length[s]\n",
    "            path = paths[s]\n",
    "            best_source = s\n",
    "#         if length < shortest_distance:\n",
    "#             shortest_distance = length\n",
    "#             best_source = source\n",
    "#             best_path = path\n",
    "\n",
    "    return best_source, length, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07ffd2-6698-42da-a26a-465db8337d36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = np.load(f'/scratch/gza5dr/Canal_Datasets/NHDShape/procssed_data/full_data/processed_images/train_img_set3_2022.npy') \n",
    "mask = np.load(f'/scratch/gza5dr/Canal_Datasets/NHDShape/procssed_data/full_data/masks/train_mask_set3_2021.npy') \n",
    "p_s = 512\n",
    "\n",
    "\n",
    "cut_1,cut_2 = img.shape[0]%p_s,img.shape[1]%p_s\n",
    "img = img[cut_1:,cut_2:,:]\n",
    "mask = mask[cut_1:,cut_2:]\n",
    "ground_truth = mask\n",
    "\n",
    "\n",
    "image_patches = patchify(img,(p_s,p_s,img.shape[2]),step=p_s)\n",
    "gt_patches = patchify(mask,(p_s,p_s),step=p_s)\n",
    "                      \n",
    "weights_I = '/scratch/gza5dr/Current_Canal_Experiments/Canal_Detection_Experiments/Proposed_Model_Pipeline/implementation/framework/final_framework/output_set3/R110_th0.5_rth0.01_4dil_resnet/models/best_it4_R110_th0.5_rth0.01_4dil_resnet.weights.h5'\n",
    "predictions = make_predictions(weights_I,image_patches,model=\"resnet\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317a6001-d88c-4b9e-87f7-c95fd8663e73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = np.array(predictions)\n",
    "f = np.squeeze(f,axis=-1)\n",
    "canal_mask = ground_truth.copy()\n",
    "full_predictions_mask_patches = f.copy()\n",
    "\n",
    "water_mask = ground_truth.copy()\n",
    "water_mask[water_mask!=2] = 0\n",
    "\n",
    "canal_mask[canal_mask==3] = 1\n",
    "canal_mask[canal_mask>1] = 0\n",
    "\n",
    "\n",
    "full_predictions_mask_patches[full_predictions_mask_patches>=th] = 1\n",
    "full_predictions_mask_patches[full_predictions_mask_patches<th] = 0\n",
    "\n",
    "full_predictions_mask = unpatchify(full_predictions_mask_patches, ground_truth.shape) #f\n",
    "\n",
    "\n",
    "kernel = np.ones((3, 3), np.uint8) \n",
    "new_mask = cv2.dilate(canal_mask,kernel=kernel,iterations=5)\n",
    "new_mask = new_mask + full_predictions_mask\n",
    "new_mask[new_mask>1] = 1\n",
    "H = cv2.erode(new_mask, kernel=kernel,iterations=5)\n",
    "full_h = water_mask+H\n",
    "full_h[full_h==3]=1\n",
    "full_h_patches = patchify(full_h,(p_s,p_s),step=p_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc199e0d-6792-4942-9571-caef97e6ccdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_common_rows(a, b):\n",
    "    # Convert b to a set of tuples for faster lookup\n",
    "    b_set = set(map(tuple, b))\n",
    "    \n",
    "    # Use a list comprehension to find common rows while preserving order\n",
    "    common = [row for row in a if tuple(row) in b_set]\n",
    "    \n",
    "    return np.array(common)\n",
    "\n",
    "gt_patches[gt_patches==3]=1\n",
    "\n",
    "all_mask = ground_truth.copy()\n",
    "all_mask[all_mask==3]=1\n",
    "\n",
    "canal_mask = ground_truth.copy()\n",
    "canal_mask[canal_mask==3] = 1\n",
    "canal_mask[canal_mask>1] = 0\n",
    "\n",
    "###Main GT\n",
    "water_index = get_water_source_index_patch(all_mask,gt_patches)\n",
    "directly_connected_patches,not_connected_patches = directly_connected_1s_patch(all_mask,gt_patches,water_index)\n",
    "reachable_nodes, unreachable_nodes = bfs_patch(gt_patches, directly_connected_patches, directly_connected_patches,not_connected_patches)\n",
    "print(f\"Number of reachable Canal pixels:{len(reachable_nodes)}\")\n",
    "\n",
    "unreachable_nodes = np.where(unreachable_nodes == 1)\n",
    "i,j,d_row_indices, d_col_indices = unreachable_nodes\n",
    "unreachable_nodes_index_pairs = list(zip(i,j,d_row_indices, d_col_indices))\n",
    "unreachable_nodes_index_pairs = np.array(unreachable_nodes_index_pairs)\n",
    "print(f\"Number of unreachable Canal pixels in ground truth: {len(unreachable_nodes_index_pairs)}\")\n",
    "\n",
    "## For H\n",
    "directly_connected_preds,not_connected_preds = directly_connected_1s_patch(full_h,full_h_patches,water_index)\n",
    "reachable_nodes_H, unreachable_nodes_H = bfs_patch(full_h_patches, directly_connected_preds, directly_connected_preds,not_connected_preds)\n",
    "print(f\"Number of reachable Canal pixels:{len(reachable_nodes_H)}\")\n",
    "\n",
    "\n",
    "unreachable_nodes_H = np.where(unreachable_nodes_H == 1)\n",
    "i,j,d_row_indices, d_col_indices = unreachable_nodes_H\n",
    "unreachable_nodes_index_pairs_H = list(zip(i,j,d_row_indices, d_col_indices))\n",
    "unreachable_nodes_index_pairs_H = np.array(unreachable_nodes_index_pairs_H)\n",
    "print(f\"Number of unreachable Canal pixels in H: {len(unreachable_nodes_index_pairs_H)}\")\n",
    "\n",
    "\n",
    "a = np.array(unreachable_nodes_index_pairs)\n",
    "b = np.array(unreachable_nodes_index_pairs_H)\n",
    "\n",
    "result = find_common_rows(a, b)\n",
    "print(\"Number of common canal pixels in GT and H\",len(result))\n",
    "\n",
    "curr_unreachable_nodes = unreachable_nodes_index_pairs\n",
    "common_unreachable_nodes = result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f84ea-5bee-46f9-8c38-5d6771bc1c33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_isolated_points(data,full_h_patches):\n",
    "    data_set = set(tuple(point) for point in data)  # Convert array to a set of tuples for fast lookup\n",
    "    visited = set()  # To track visited points\n",
    "    endpoints = []  # List to store endpoints\n",
    "    p_i,p_j,p_rows,p_columns = full_h_patches.shape\n",
    "\n",
    "    # Directions corresponding to N, NE, E, SE, S, SW, W, NW\n",
    "    directions = [(0, 1), (1, 1), (1, 0), (1, -1), (0, -1), (-1, -1), (-1, 0), (-1, 1)]\n",
    "\n",
    "    for point in data:\n",
    "        neighbors = []\n",
    "        point_tuple = tuple(point)\n",
    "        i,j,x,y = point_tuple\n",
    "        if point_tuple not in visited:\n",
    "            # Check all 8 directions and count neighbors\n",
    "            for dx, dy in directions:\n",
    "                nx, ny = x + dx, y + dy\n",
    "                n_i,n_j= i,j\n",
    "\n",
    "                if 0>nx or nx>=p_rows:\n",
    "                    n_i = i+dx\n",
    "                    nx = 511 if nx == -1 else 0 if nx == 512 else nx\n",
    "\n",
    "                if 0>ny or ny>=p_columns:\n",
    "                    n_j = j+dy\n",
    "                    ny = 511 if ny == -1 else 0 if ny == 512 else ny\n",
    "                    \n",
    "                if (n_i,n_j,nx, ny) in data_set:\n",
    "                    neighbors.append((n_i,n_j,nx, ny))\n",
    "\n",
    "            num_neighbors = len(neighbors)\n",
    "            \n",
    "            if num_neighbors <= 1:\n",
    "                endpoints.append(point)  # Zero or one neighbor, so it's an endpoint\n",
    "                \n",
    "            # Mark point and its neighbors as visited\n",
    "            visited.add(point_tuple)\n",
    "            # visited.update(neighbors)\n",
    "\n",
    "    return np.array(endpoints),visited\n",
    "\n",
    "data = np.array(curr_unreachable_nodes)\n",
    "\n",
    "terminals,visited = find_isolated_points(data,gt_patches)\n",
    "print(len(terminals))\n",
    "\n",
    "\n",
    "unique_patch_nodes = set()\n",
    "\n",
    "for i,j,_,_ in curr_unreachable_nodes:\n",
    "    unique_patch_nodes.add((i,j))\n",
    "\n",
    "print(\"Number of unique patches - for unreachable nodes\",len(unique_patch_nodes))\n",
    "\n",
    "unique_patch_terminals = set()\n",
    "\n",
    "for i,j,_,_ in terminals:\n",
    "    unique_patch_terminals.add((i,j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aadd9d4-e4be-4ae1-b130-a673ebdb77c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def get_neighbors_fast(i, j, x, y, R, shape, patch_size):\n",
    "    n, m = shape\n",
    "    X_L = x + (i * patch_size)\n",
    "    Y_L = y + (j * patch_size)\n",
    "    neighbors = []\n",
    "    for dx in range(-R, R+1):\n",
    "        for dy in range(-R, R+1):\n",
    "            if dx == 0 and dy == 0:\n",
    "                continue\n",
    "            nx, ny = X_L + dx, Y_L + dy\n",
    "            if 0 <= nx < n and 0 <= ny < m:\n",
    "                p_i, p_j = nx // patch_size, ny // patch_size\n",
    "                p_x, p_y = nx % patch_size, ny % patch_size\n",
    "                neighbors.append((p_i, p_j, p_x, p_y))\n",
    "    return neighbors\n",
    "\n",
    "@jit(nopython=True)\n",
    "def process_edge_points(u, w, X_r, R, shape, patch_size, th):\n",
    "    new_points = []\n",
    "    for edge_point in u:\n",
    "        i, j, x, y = edge_point\n",
    "        neighbors = get_neighbors_fast(i, j, x, y, R, shape, patch_size)\n",
    "        for neighbor in neighbors:\n",
    "            i, j, x, y = neighbor\n",
    "            if w[i, j, x, y] > th and X_r[i, j, x, y] == 0:\n",
    "                X_r[i, j, x, y] = int(1 / w[i, j, x, y])\n",
    "                new_points.append((i, j, x, y))\n",
    "    return new_points, X_r\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f = np.array(predictions)\n",
    "f = np.squeeze(f,axis=-1)\n",
    "w = f.copy()\n",
    "\n",
    "X_r = full_h_patches.copy()\n",
    "u = terminals.copy()\n",
    "X = full_h_patches.copy()\n",
    "r_th = 0.1\n",
    "new_points = []\n",
    "\n",
    "new_points, X_r = process_edge_points(u, w, X_r, R, full_h.shape, patch_size, r_th)\n",
    "\n",
    "print(X_r.shape)\n",
    "\n",
    "# X_r[X_r>=1] = int(1/.9)\n",
    "X_r[X_r==0] = large_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fec852-71d6-4e36-855f-87f0b35488bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_vector_to_point(point, vector):\n",
    "    return (point[0] + vector[0], point[1] + vector[1])\n",
    "def points_within_radius(center, radius, points):\n",
    "    # Convert center to a numpy array\n",
    "    center = np.array(center)\n",
    "    \n",
    "    # Calculate the squared distances from each point in the array to the center\n",
    "    distances = np.sqrt(np.sum((points - center) ** 2, axis=1))\n",
    "    \n",
    "    # Find points where the distance is less than or equal to the radius\n",
    "    within_radius = points[distances <= radius]\n",
    "    \n",
    "    return within_radius\n",
    "\n",
    "def find_edge_points(full_h_patches,data):\n",
    "    data_set = set(tuple(point) for point in data)  # Convert array to a set of tuples for fast lookup\n",
    "    visited = set()  # To track visited points\n",
    "    edgepoints = []  # List to store endpoints\n",
    "    p_i,p_j,p_rows,p_columns = full_h_patches.shape\n",
    "\n",
    "    # Directions corresponding to N, NE, E, SE, S, SW, W, NW\n",
    "    directions = [(0, 1), (1, 1), (1, 0), (1, -1), (0, -1), (-1, -1), (-1, 0), (-1, 1)]\n",
    "\n",
    "    for point in data:\n",
    "        neighbors = []\n",
    "        point_tuple = tuple(point)\n",
    "        i,j,x,y = point_tuple\n",
    "        if point_tuple not in visited:\n",
    "            # Check all 8 directions and count neighbors\n",
    "            for dx, dy in directions:\n",
    "                nx, ny = x + dx, y + dy\n",
    "                n_i,n_j= i,j\n",
    "\n",
    "                if 0>nx or nx>=p_rows:\n",
    "                    n_i = i+dx\n",
    "                    nx = 511 if nx == -1 else 0 if nx == 512 else nx\n",
    "\n",
    "                if 0>ny or ny>=p_columns:\n",
    "                    n_j = j+dy\n",
    "                    ny = 511 if ny == -1 else 0 if ny == 512 else ny\n",
    "                    \n",
    "                if (n_i,n_j,nx, ny) in data_set:\n",
    "                    neighbors.append((n_i,n_j,nx, ny))\n",
    "\n",
    "            num_neighbors = len(neighbors)\n",
    "            \n",
    "            if num_neighbors < 8:\n",
    "                edgepoints.append(point)  # Zero or one neighbor, so it's an endpoint\n",
    "                \n",
    "            # Mark point and its neighbors as visited\n",
    "            visited.add(point_tuple)\n",
    "            # visited.update(neighbors)\n",
    "\n",
    "    return np.array(edgepoints),visited\n",
    "\n",
    "def find_source_terminal_pair(source_terms,X_L,Y_L,i,j,radius):\n",
    "    n_reachable_terms = []\n",
    "    directions = [(0,0),(0, 1), (0, -1), (1, 0), (-1, 0),\n",
    "     (-1, -1), (1, -1), (1, 1), (-1, 1)]\n",
    "    \n",
    "    resulting_points = np.array([(i, j)]) + directions\n",
    "    mask = np.isin(source_terms[:, :2], resulting_points).all(axis=1)\n",
    "    reachable_terms = source_terms[mask, 2:] + source_terms[mask, :2] * 512\n",
    "    \n",
    "    if(len(reachable_terms)!=0):\n",
    "        n_reachable_terms = points_within_radius((X_L,Y_L), radius, reachable_terms)\n",
    "    return n_reachable_terms\n",
    "\n",
    "data = np.array(water_index)\n",
    "water_edges,visited = find_edge_points(gt_patches,data)\n",
    "a = reachable_nodes.copy()\n",
    "a = np.array(list(a))\n",
    "source_terms = np.concatenate((a,water_edges))\n",
    "source_terminal_pair = {}\n",
    "tot_sp = 0\n",
    "for terminal in terminals:\n",
    "    i,j,x,y = terminal\n",
    "    X_L = (x) + (i*512) \n",
    "    Y_L = (y) + (j*512)\n",
    "    pair_val = find_source_terminal_pair(source_terms,X_L,Y_L,i,j,R)\n",
    "    tot_sp += len(pair_val)\n",
    "    source_terminal_pair[f'{(X_L,Y_L)}'] = (pair_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Save using Pickle\n",
    "# file_path = get_source_terminal_pair_path(years)\n",
    "# with open(file_path, 'wb') as file:\n",
    "#     pickle.dump(source_terminal_pair, file)\n",
    "\n",
    "# # Load the dictionary back\n",
    "# with open(file_path, 'rb') as file:\n",
    "#     source_terminal_pair = pickle.load(file)\n",
    "#     print(len(source_terminal_pair))\n",
    "\n",
    "print(\"Number of Source Terminal Pair\", tot_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a5d8d-fd8b-427f-bd8f-67aae46d1dac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = []\n",
    "terminal_paths = {}\n",
    "netwk = unpatchify(X_r, full_h.shape)\n",
    "cnt = 0\n",
    "for terminal in terminals:\n",
    "    i,j,x,y = terminal\n",
    "    X_L = (x) + (i*512) \n",
    "    Y_L = (y) + (j*512)\n",
    "    t_points = (X_L,Y_L)\n",
    "    source_points = source_terminal_pair[f'{(X_L,Y_L)}']\n",
    "    goals = list(map(tuple, source_points))\n",
    "    if len(goals)!= 0:\n",
    "        netwk_t = create_subgraph_around_terminal(netwk,t_points, 110)\n",
    "        best_source, shortest_distance, best_path = find_shortest_path(netwk_t,t_points,goals)\n",
    "        if best_source != None:\n",
    "            cnt = cnt+1\n",
    "            terminal_paths[f'{t_points}'] = best_path\n",
    "            paths.extend(best_path)\n",
    "\n",
    "print('terminals got connected',cnt)\n",
    "file_path = generated_paths_from_terminals(years)\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(terminal_paths, file)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db806c0-760f-427e-a56f-c54e09d9b558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218b17a2-8342-4a3a-be37-6ce6d5193f28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reachable_canal = np.load('/scratch/gza5dr/Current_Canal_Experiments/Canal_Detection_Experiments/Proposed_Model_Pipeline/implementation/framework/final_framework/output_set3/R110_th0.5_rth0.01_4dil_resnet/reachable_nodes_H_it0_110_0.5_0.01_combined.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2babd-20da-476f-94fc-43409fd594a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unreachable_canal = np.load('/scratch/gza5dr/Current_Canal_Experiments/Canal_Detection_Experiments/Proposed_Model_Pipeline/implementation/framework/final_framework/output_set3/R110_th0.5_rth0.01_4dil_resnet/unreachable_nodes_H_it0_110_0.5_0.01_combined.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b015544-848b-4968-9b35-86854394ac93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unreachable_canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6162ee52-d5bb-4956-9f0a-2b5d0e33842d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = reachable_canal[(reachable_canal[:, 0] == 9) & (reachable_canal[:, 1] == 10)]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25ec477-18fb-41c5-b7b6-d9c76f5f2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "patch_size = 512\n",
    "def visulization(display_list, figsize=(15, 10)):\n",
    "    _, axes = plt.subplots(nrows=1, ncols=len(display_list), figsize=figsize)\n",
    "    for i in range(len(display_list)):\n",
    "            axes[i].imshow(display_list[i])\n",
    "            axes[i].axis('off') \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "for terms in list(terminal_paths.keys()):\n",
    "    coordinate_tuple = eval(terms)\n",
    "    X_L,Y_L = coordinate_tuple\n",
    "    path = terminal_paths[terms]\n",
    "    print(len(path))\n",
    "    x,y,p_x,p_y = (int(X_L/patch_size),int(Y_L/patch_size),X_L%patch_size,Y_L%patch_size)\n",
    "    ck2=full_h_patches[x,y,:,:].copy()\n",
    "    ck1=full_h_patches[x,y,:,:].copy()\n",
    "    bp = set()\n",
    "    for a,b,c in path:\n",
    "        bp.add((a,b))\n",
    "    for k,l in bp:\n",
    "        _,_,k,l = (int(k/patch_size),int(l/patch_size),k%patch_size,l%patch_size)\n",
    "        cv2.circle(ck2, (l,k), radius=2, color=(6, 0, 0), thickness=3)\n",
    "    cv2.circle(ck2, (p_y,p_x), radius=5, color=(7, 0, 0), thickness=5)\n",
    "    result = reachable_canal[(reachable_canal[:, 0] == x) & (reachable_canal[:, 1] == y)]\n",
    "    result2 = unreachable_canal[(unreachable_canal[:, 0] == x) & (unreachable_canal[:, 1] == y)]\n",
    "    for _,_,k,l in result:\n",
    "        cv2.circle(ck1, (l,k), radius=2, color=(8, 0, 0), thickness=5)\n",
    "        cv2.circle(ck2, (l,k), radius=2, color=(8, 0, 0), thickness=5)\n",
    "    for _,_,k,l in result2:\n",
    "        cv2.circle(ck1, (l,k), radius=2, color=(12, 0, 0), thickness=5)\n",
    "        cv2.circle(ck2, (l,k), radius=2, color=(12, 0, 0), thickness=5)\n",
    "    p = predictions[x,y,:,:]\n",
    "    # p[p>0.01]=1\n",
    "    # visulization([image_patches[x,y,0,:,:],gt_patches[x,y,:,:],predictions[x,y,:,:],ck1,ck2])\n",
    "    visulization([image_patches[x,y,0,:,:],predictions[x,y,:,:],ck1,ck2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c2e1b8-9442-4553-95ba-32fd7ea103dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Network Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f8737-876b-44d7-b5c4-b6d5d6b1868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_utils import *\n",
    "\n",
    "def find_isolated_points(data):\n",
    "    data_set = set(tuple(point) for point in data)  # Convert array to a set of tuples for fast lookup\n",
    "    visited = set()  # To track visited points\n",
    "    endpoints = []  # List to store endpoints\n",
    "    p_i,p_j,p_rows,p_columns = full_h_patches.shape\n",
    "\n",
    "    # Directions corresponding to N, NE, E, SE, S, SW, W, NW\n",
    "    directions = [(0, 1), (1, 1), (1, 0), (1, -1), (0, -1), (-1, -1), (-1, 0), (-1, 1)]\n",
    "\n",
    "    for point in data:\n",
    "        neighbors = []\n",
    "        point_tuple = tuple(point)\n",
    "        i,j,x,y = point_tuple\n",
    "        if point_tuple not in visited:\n",
    "            # Check all 8 directions and count neighbors\n",
    "            for dx, dy in directions:\n",
    "                nx, ny = x + dx, y + dy\n",
    "                n_i,n_j= i,j\n",
    "\n",
    "                if 0>nx or nx>=p_rows:\n",
    "                    n_i = i+dx\n",
    "                    nx = 511 if nx == -1 else 0 if nx == 512 else nx\n",
    "\n",
    "                if 0>ny or ny>=p_columns:\n",
    "                    n_j = j+dy\n",
    "                    ny = 511 if ny == -1 else 0 if ny == 512 else ny\n",
    "                    \n",
    "                if (n_i,n_j,nx, ny) in data_set:\n",
    "                    neighbors.append((n_i,n_j,nx, ny))\n",
    "\n",
    "            num_neighbors = len(neighbors)\n",
    "            \n",
    "            if num_neighbors <= 1:\n",
    "                endpoints.append(point)  # Zero or one neighbor, so it's an endpoint\n",
    "                \n",
    "            # Mark point and its neighbors as visited\n",
    "            visited.add(point_tuple)\n",
    "            # visited.update(neighbors)\n",
    "\n",
    "    return np.array(endpoints),visited\n",
    "    \n",
    "def find_common_rows(a, b):\n",
    "    # Convert b to a set of tuples for faster lookup\n",
    "    b_set = set(map(tuple, b))\n",
    "\n",
    "    # Use a list comprehension to find common rows while preserving order\n",
    "    common = [[a,b,c,d] for a,b,c,d in a if tuple([c+(a*512),d+(b*512)]) in b_set]\n",
    "\n",
    "    return np.array(common)\n",
    "\n",
    "for i in range(4):\n",
    "    print(years[i])\n",
    "    year = years[i]\n",
    "    image_patches = get_img_patches(year)\n",
    "    gt_patches = get_gt_patches(year)\n",
    "    predictions = get_predictions(year)\n",
    "    X_r = np.load(get_X_r_path(year))\n",
    "    full_h = get_full_h(year)\n",
    "    full_h_patches = get_full_h_patches(year)\n",
    "    terminals = get_terminals(year)\n",
    "    n_all_mask = full_h.copy()\n",
    "    added_nodes = 0\n",
    "    file_path = generated_paths_from_terminals(year)\n",
    "    with open(file_path, 'rb') as file:\n",
    "        terminal_paths = pickle.load(file)\n",
    "    paths = []\n",
    "    for terms in list(terminal_paths.keys()):\n",
    "        paths.extend(terminal_paths[terms])\n",
    "    for x,y,_ in paths:\n",
    "        if n_all_mask[x,y]!=1:\n",
    "            added_nodes += 1\n",
    "        n_all_mask[x,y] = 1\n",
    "    print(added_nodes)\n",
    "    water_index = get_water_source_index(n_all_mask)\n",
    "    directly_connected_full,not_connected_full = directly_connected_1s(n_all_mask,water_index)\n",
    "    reachable_nodes, unreachable_nodes = bfs(n_all_mask, directly_connected_full, directly_connected_full,not_connected_full)\n",
    "    print(f\"Number of reachable Canal pixels:{len(reachable_nodes)}\")\n",
    "    \n",
    "    \n",
    "    unreachable_nodes_N = np.where(unreachable_nodes == 1)\n",
    "    d_row_indices, d_col_indices = unreachable_nodes_N\n",
    "    unreachable_nodes_index_pairs = list(zip(d_row_indices, d_col_indices))\n",
    "    unreachable_nodes_index_pairs = np.array(unreachable_nodes_index_pairs)\n",
    "    np.save(f\"{outputh_path}/it_1{y}.npy\",n_all_mask)\n",
    "    curr_unreachable_nodes = np.load(get_curr_unreachable_nodes_path(year))\n",
    "    print(f\"Current Number of unreachable Canal pixels:{len(unreachable_nodes_index_pairs)}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    b = np.array(unreachable_nodes_index_pairs)\n",
    "    a = np.array(curr_unreachable_nodes)\n",
    "    c = np.load(get_unreachable_nodes_path(years[i]))\n",
    "    \n",
    "    print(f\"Prev Number of unreachable Canal pixels:{len(curr_unreachable_nodes)}\")\n",
    "\n",
    "    result = find_common_rows(a, b)\n",
    "    result2 = find_common_rows(a, c)\n",
    "    print(f\"Unreachable Canal pixels Left in main GT:{len(result)}\")\n",
    "    print(f\"Unreachable Canal pixels Left:{len(result)}\")\n",
    "    np.save(f\"{outputh_path}/it_1_{year}_mask.npy\",n_all_mask)\n",
    "    \n",
    "    \n",
    "    data = np.array(b)\n",
    "    terminals,visited = find_isolated_points(data)\n",
    "    # print(\"Endpoints:\", terminals)\n",
    "    print(len(terminals)\n",
    "          \n",
    "    unique_patch_nodes = set()\n",
    "\n",
    "    for i,j,_,_ in curr_unreachable_nodes:\n",
    "        unique_patch_nodes.add((i,j))\n",
    "\n",
    "    print(len(unique_patch_nodes))\n",
    "\n",
    "    unique_patch_terminals = set()\n",
    "\n",
    "    for i,j,_,_ in terminals:\n",
    "        unique_patch_terminals.add((i,j))\n",
    "\n",
    "    print(len(unique_patch_terminals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a5dee-2fdb-40d8-85b1-0373f6a5a7fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558d696-68c4-48f4-b00a-fc2e7ccbf32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "p_s = 512\n",
    "\n",
    "outputh_path = '/scratch/gza5dr/Current_Canal_Experiments/Canal_Detection_Experiments/Proposed_Model_Pipeline/implementation/framework/output_v1_it1'\n",
    "curr_unreachable_nodes1 = result\n",
    "# curr_unreachable_nodes=np.load('/scratch/gza5dr/Current_Canal_Experiments/Canal_Detection_Experiments/Proposed_Model_Pipeline/implementation/framework/files/curr_unreachable_nodes.npy')\n",
    "full_h = n_all_mask\n",
    "full_h_patches = patchify(full_h,(p_s,p_s),step=p_s)\n",
    "ground_truth = np.load(f'/scratch/gza5dr/Canal_Datasets/full_data/masks/2021.npy')\n",
    "cut_1,cut_2 = ground_truth.shape[0]%p_s,ground_truth.shape[1]%p_s\n",
    "ground_truth = ground_truth[cut_1:,cut_2:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage with your data\n",
    "data = np.array(curr_unreachable_nodes1)\n",
    "\n",
    "terminals,visited = find_isolated_points(data)\n",
    "# print(\"Endpoints:\", terminals)\n",
    "print(len(terminals))\n",
    "\n",
    "\n",
    "unique_patch_nodes = set()\n",
    "\n",
    "for i,j,_,_ in curr_unreachable_nodes:\n",
    "    unique_patch_nodes.add((i,j))\n",
    "    \n",
    "print(len(unique_patch_nodes))\n",
    "\n",
    "unique_patch_terminals = set()\n",
    "\n",
    "for i,j,_,_ in terminals:\n",
    "    unique_patch_terminals.add((i,j))\n",
    "    \n",
    "print(len(unique_patch_terminals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7218c6b-b778-4d9c-ae45-ecbf82cfa9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Number of unreachable Canal pixels:{len(unreachable_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683410e-7558-41a3-9f2f-137ffb1ee398",
   "metadata": {},
   "outputs": [],
   "source": [
    "unreachable_nodes_N = np.where(unreachable_nodes == 1)\n",
    "d_row_indices, d_col_indices = unreachable_nodes_N\n",
    "unreachable_nodes_index_pairs = list(zip(d_row_indices, d_col_indices))\n",
    "unreachable_nodes_index_pairs = np.array(unreachable_nodes_index_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b949f741-3410-45d1-81f3-776136ec9ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unreachable_nodes_index_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435585eb-024e-4f30-a891-ca7d7bc5fff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prev = 132224\n",
    "current = len(unreachable_nodes)\n",
    "print(prev-current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc60cc2-2dab-477a-857a-7b210c4b04e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unreachable_nodes_index_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65abf63c-f947-4d8e-8b58-8e4243b6de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{outputh_path}/it_1.npy\",n_all_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aea2fb-73a2-4970-b392-2e9c158550ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{outputh_path}/it_1_unreachable.npy\",n_all_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a161d4b6-21aa-48d8-8c0e-92f56ad8e4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "curr_unreachable_nodes = np.load(f'{outputh_path}/curr_unreachable_nodes.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02737aa-b3e8-4229-848b-aad5d3e8a030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_common_rows(a, b):\n",
    "    # Convert b to a set of tuples for faster lookup\n",
    "    b_set = set(map(tuple, b))\n",
    "    \n",
    "    # Use a list comprehension to find common rows while preserving order\n",
    "    common = [[a,b,c,d] for a,b,c,d in a if tuple([c+(a*512),d+(b*512)]) in b_set]\n",
    "    \n",
    "    return np.array(common)\n",
    "\n",
    "b = np.array(unreachable_nodes_index_pairs)\n",
    "a = np.array(curr_unreachable_nodes)\n",
    "\n",
    "result = find_common_rows(a, b)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754a8fa3-3b8c-4f2c-8d10-84c84ddf67cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e6d7e-464d-40dd-a82e-1e7cdbf2d3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_common_rows(a_s, b_s):\n",
    "    # Convert b to a set of tuples for faster lookup\n",
    "    \n",
    "    c_set = [[m, n] for m, n, o, p in b_s]\n",
    "    c_set = set(map(tuple, c_set))\n",
    "    \n",
    "    # Use a list comprehension to find common rows while preserving order\n",
    "    common = [[a,b,c,d] for a,b,c,d in a_s if tuple([a,b]) in c_set]\n",
    "    \n",
    "    return np.array(common)\n",
    "\n",
    "b = np.array(result)\n",
    "a = np.array(curr_unreachable_nodes)\n",
    "\n",
    "result = find_common_rows(a, b)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd64814-95a5-4667-9ae7-bdf8a51fa8a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3950f18-3739-48c7-a5fc-56415b796645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f4bf1f-24ea-4efa-865f-813469c50995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.13.0",
   "language": "python",
   "name": "tensorflow-2.13.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
